# Awesome-SLMs [![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome) [![PR's Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat)](http://makeapullrequest.com) ![Github Last Commit](https://img.shields.io/github/last-commit/lif314/Awesome-SLMs)


## üè† About
This repo contains a curative list of **Small (Vision)-Language Models**. This is an active repository, you can watch for following the latest advances. If you find this repository useful, please consider STARing ‚≠ê this list. Feel free to share this list with others!


<details open="open" style='padding: 10px; border-radius:5px 30px 30px 5px; border-style: solid; border-width: 1px;'>
  <summary>Table of Contents</summary>
  <ol>
    <li>
      <a href="#SurveyCollection">Survey/Collection</a>
    </li>
    <li>
      <a href="#Blogs">Blogs</a>
    </li>
    <li>
      <a href="#Insights">Insights</a>
    </li>
    <li>
      <a href="#SmallLMs">SmallLMs</a>
    </li>
    <li>
      <a href="#SmallVLMs">SmallVLMs</a>
    </li>
    <li>
      <a href="#SmallVLAs">SmallVLAs</a>
    </li>
     <li>
      <a href="#SpatialVLMs">SpatialVLMs</a>
    </li>
  </ol>
</details>

## Survey/Collection
- Awesome-SLM: a curated list of Small Language Model. [Github](https://github.com/ro-ko/Awesome-SLM) ![Stars](https://img.shields.io/github/stars/ro-ko/Awesome-SLM?style=social) ![Last Commit](https://img.shields.io/github/last-commit/ro-ko/Awesome-SLM)
- Awesome Small Language Models. [Github](https://github.com/slashml/awesome-small-language-models) ![Stars](https://img.shields.io/github/stars/slashml/awesome-small-language-models?style=social) ![Last Commit](https://img.shields.io/github/last-commit/slashml/awesome-small-language-models)
- Domain-Specific Small Language Models Book. [Github](https://github.com/virtualramblas/Domain-Specific-Small-Language-Models) ![Stars](https://img.shields.io/github/stars/virtualramblas/Domain-Specific-Small-Language-Models?style=social) ![Last Commit](https://img.shields.io/github/last-commit/virtualramblas/Domain-Specific-Small-Language-Models)
- Survery of Small Language Models. [Github](https://github.com/OpenCSGs/Awesome-SLMs) ![Stars](https://img.shields.io/github/stars/OpenCSGs/Awesome-SLMs?style=social) ![Last Commit](https://img.shields.io/github/last-commit/OpenCSGs/Awesome-SLMs)
- Small VLM - a bunnycore Collection. [HF Collection](https://huggingface.co/collections/bunnycore/small-vlm)
- Phi Cookbook: Hands-On Examples with Microsoft's Phi Models. [Github](https://github.com/microsoft/PhiCookBook) ![Stars](https://img.shields.io/github/stars/microsoft/PhiCookBook?style=social) ![Last Commit](https://img.shields.io/github/last-commit/microsoft/PhiCookBook)
- Tiny VLMs Lab: interactive web application. [Github](https://github.com/PRITHIVSAKTHIUR/Tiny-VLMs-Lab) ![Stars](https://img.shields.io/github/stars/PRITHIVSAKTHIUR/Tiny-VLMs-Lab?style=social) ![Last Commit](https://img.shields.io/github/last-commit/PRITHIVSAKTHIUR/Tiny-VLMs-Lab)


## Blogs
- Â∞èÊ®°ÂûãÂ±ÇÊï∞Â•ΩÁéÑÂ≠¶Ôºö12/32/64Â±ÇÊïàÊûúÂ•ΩÔºå16/24/48/Â±ÇÊïàÊûúÁ≥ü. [Zhihu](https://zhuanlan.zhihu.com/p/1993674796538565507) [Source](https://huggingface.co/blog/codelion/optimal-model-architecture) `70M`
- qwen3-0.6BËøôÁßçÂ∞èÊ®°ÂûãÊúâ‰ªÄ‰πàÂÆûÈôÖÊÑè‰πâÂíåÁî®ÈÄîÂêóÔºü [Zhihu](https://www.zhihu.com/question/1900664888608691102)
- Small Language Models are the Future of Agentic AI, NVIDIA Research. [Paper](https://arxiv.org/abs/2506.02153), [Website](https://research.nvidia.com/labs/lpr/slm-agents/), [Blog](https://developer.nvidia.com/blog/how-small-language-models-are-key-to-scalable-agentic-ai/)
- Small Language Models (SLM): A Comprehensive Overview. [Blog](https://huggingface.co/blog/jjokah/small-language-model)
- What are small language models? IBM Thinker. [Blog](https://www.ibm.com/think/topics/small-language-models)
- What Are Small Language Models (SLMs)? Microsoft Cloud Team. [Blog](https://azure.microsoft.com/en-us/resources/cloud-computing-dictionary/what-are-small-language-models)
- The Best Open-Source Small Language Models (SLMs) in 2026. [BentoML Blog](https://www.bentoml.com/blog/the-best-open-source-small-language-models)


## Insights
- An Information Theoretic Perspective on Agentic System Design, arXiv 2025. [Paper](https://www.arxiv.org/abs/2512.21720) `SLMs are all you need in Agent system.`
- :fire: Dhara-70M: The Optimal Architecture for Small Language Models. `70M` [Blog](https://huggingface.co/blog/codelion/optimal-model-architecture) [Model](https://huggingface.co/codelion/dhara-70m) `For SLMs, the depth-to-width ratio is more important than the model architecture.`
- Return of the Encoder: Efficient Small Language Models, arXiv 2025. [Paper](https://arxiv.org/pdf/2501.16273), [Github](https://github.com/microsoft/encoder-decoder-slm) ![Stars](https://img.shields.io/github/stars/microsoft/encoder-decoder-slm?style=social) ![Last Commit](https://img.shields.io/github/last-commit/microsoft/encoder-decoder-slm) `Encoder-decoder models inherently outperform decoder-only architectures before any optimizations.`

## SmallLMs
> [Github]() ![Stars](https://img.shields.io/github/stars/?style=social) ![Last Commit](https://img.shields.io/github/last-commit/)
- Qwen3. `0.6B-235B` [Paper](https://arxiv.org/abs/2505.09388) [Github](https://github.com/QwenLM/Qwen3) ![Stars](https://img.shields.io/github/stars/QwenLM/Qwen3?style=social) ![Last Commit](https://img.shields.io/github/last-commit/QwenLM/Qwen3)
- Building a Small Language Model(SLM) from Scratch. [Github](https://github.com/ChaitanyaK77/Building-a-Small-Language-Model-SLM-) ![Stars](https://img.shields.io/github/stars/ChaitanyaK77/Building-a-Small-Language-Model-SLM-?style=social) ![Last Commit](https://img.shields.io/github/last-commit/ChaitanyaK77/Building-a-Small-Language-Model-SLM-)
- SmallDoge: Ultra-Fast Small Language Models, `20M-320M`, [Github](https://github.com/SmallDoges/small-doge) ![Stars](https://img.shields.io/github/stars/SmallDoges/small-doge?style=social) ![Last Commit](https://img.shields.io/github/last-commit/SmallDoges/small-doge)  
- SmolLM2 (Language Model), `135M-1.7B`, [Github](https://github.com/huggingface/smollm) ![Stars](https://img.shields.io/github/stars/huggingface/smollm?style=social) ![Last Commit](https://img.shields.io/github/last-commit/huggingface/smollm)
- SmolLM3 (Language Model), `3B`, [Github](https://github.com/huggingface/smollm) ![Stars](https://img.shields.io/github/stars/huggingface/smollm?style=social) ![Last Commit](https://img.shields.io/github/last-commit/huggingface/smollm)
- SLM-SQL: An Exploration of Small Language Models for Text-to-SQL. [Paper](https://arxiv.org/abs/2507.22478), [Github](https://github.com/CycloneBoy/slm_sql) ![Stars](https://img.shields.io/github/stars/CycloneBoy/slm_sql?style=social) ![Last Commit](https://img.shields.io/github/last-commit/CycloneBoy/slm_sql)
- Tiny language models (pre-training and fine-tuning a compact BERT model ). [Paper](https://arxiv.org/abs/2507.14871),[Github](https://github.com/Rg32601/Tiny-Language-Models) ![Stars](https://img.shields.io/github/stars/Rg32601/Tiny-Language-Models?style=social) ![Last Commit](https://img.shields.io/github/last-commit/Rg32601/Tiny-Language-Models)



##  SmallVLMs
> [Github]() ![Stars](https://img.shields.io/github/stars/?style=social) ![Last Commit](https://img.shields.io/github/last-commit/)
- NVILA: Optimized Vision Language Models, NVIDIA. `2B-15B`. [Model](https://huggingface.co/collections/Efficient-Large-Model/nvila) [Github](https://github.com/NVlabs/VILA) ![Stars](https://img.shields.io/github/stars/NVlabs/VILA?style=social) ![Last Commit](https://img.shields.io/github/last-commit/NVlabs/VILA)
- Fine-tuning Qwen-VL Series. [Github](https://github.com/2U1/Qwen-VL-Series-Finetune) ![Stars](https://img.shields.io/github/stars/2U1/Qwen-VL-Series-Finetune?style=social) ![Last Commit](https://img.shields.io/github/last-commit/2U1/Qwen-VL-Series-Finetune)
-  Qwen3-Embedding and Qwen3-Reranker. `0.6B-8B`  [Github](https://github.com/QwenLM/Qwen3-VL-Embedding) ![Stars](https://img.shields.io/github/stars/QwenLM/Qwen3-VL-Embedding?style=social) ![Last Commit](https://img.shields.io/github/last-commit/QwenLM/Qwen3-VL-Embedding)
- :fire: Qwen3-VL. `2B-235B` [Paper](https://arxiv.org/pdf/2511.21631) [Github](https://github.com/QwenLM/Qwen3-VL) ![Stars](https://img.shields.io/github/stars/QwenLM/Qwen3-VL?style=social) ![Last Commit](https://img.shields.io/github/last-commit/QwenLM/Qwen3-VL)
- Qwen3+SmolVLM: Â∞ÜSmolVLM2ÁöÑËßÜËßâÂ§¥‰∏éQwen3-0.6BÊ®°ÂûãËøõË°å‰∫ÜÊãºÊé•ÂæÆË∞É. [Github](https://github.com/ShaohonChen/Qwen3-SmVL) ![Stars](https://img.shields.io/github/stars/ShaohonChen/Qwen3-SmVL?style=social) ![Last Commit](https://img.shields.io/github/last-commit/ShaohonChen/Qwen3-SmVL)
- Qwen2.5-VL. `3B-72B` [Paper](https://arxiv.org/abs/2502.13923) [Model](https://huggingface.co/collections/Qwen/qwen25-vl) [Github](https://github.com/QwenLM/Qwen3-VL) ![Stars](https://img.shields.io/github/stars/QwenLM/Qwen3-VL?style=social) ![Last Commit](https://img.shields.io/github/last-commit/QwenLM/Qwen3-VL)
- Smol Vision: Recipes for shrinking, optimizing, customizing cutting edge vision and multimodal AI models. [Github](https://github.com/merveenoyan/smol-vision) ![Stars](https://img.shields.io/github/stars/merveenoyan/smol-vision?style=social) ![Last Commit](https://img.shields.io/github/last-commit/merveenoyan/smol-vision)
- SmolVLM (Vision Language Model), `236M-2B`, [Github](https://github.com/huggingface/smollm) ![Stars](https://img.shields.io/github/stars/huggingface/smollm?style=social) ![Last Commit](https://img.shields.io/github/last-commit/huggingface/smollm)
- nanoVLM: The simplest repository to train your VLM in pure PyTorch, `222M`, [Github](https://github.com/huggingface/nanoVLM) ![Stars](https://img.shields.io/github/stars/huggingface/nanoVLM?style=social) ![Last Commit](https://img.shields.io/github/last-commit/huggingface/nanoVLM)
- NanoVLM-Lab: Democratizing Vision-Language Model Training for Everyone, `222M`, [Github](https://github.com/akash-kamalesh/nanovlm-lab) ![Stars](https://img.shields.io/github/stars/akash-kamalesh/nanovlm-lab?style=social) ![Last Commit](https://img.shields.io/github/last-commit/akash-kamalesh/nanovlm-lab)
- Fine-tuning Florence-2 - Microsoft's Cutting-edge Vision Language Models, `0.2B/0.7B`, [Github](https://github.com/andimarafioti/florence2-finetuning) ![Stars](https://img.shields.io/github/stars/andimarafioti/florence2-finetuning?style=social) ![Last Commit](https://img.shields.io/github/last-commit/andimarafioti/florence2-finetuning)
- Bunny: A family of lightweight multimodal models. [Paper](https://arxiv.org/abs/2402.11530), [Github](https://github.com/BAAI-DCAI/Bunny) ![Stars](https://img.shields.io/github/stars/BAAI-DCAI/Bunny?style=social) ![Last Commit](https://img.shields.io/github/last-commit/BAAI-DCAI/Bunny)
- Moondream: a tiny vision language model that kicks ass and runs anywhere. `0.5B/2B`, [Github](https://github.com/vikhyat/moondream) ![Stars](https://img.shields.io/github/stars/vikhyat/moondream?style=social) ![Last Commit](https://img.shields.io/github/last-commit/vikhyat/moondream)
- MobileVLM: Vision Language Model for Mobile Devices. `1.4B/2.7B`, [Paper](https://arxiv.org/abs/2312.16886), [Github](https://github.com/Meituan-AutoML/MobileVLM) ![Stars](https://img.shields.io/github/stars/Meituan-AutoML/MobileVLM?style=social) ![Last Commit](https://img.shields.io/github/last-commit/Meituan-AutoML/MobileVLM)
- FastVLM: Efficient Vision Encoding for Vision Language Models, CVPR 2025. `0.5B/1.5B/7B`, [Paper](https://www.arxiv.org/abs/2412.13303), [Github](https://github.com/apple/ml-fastvlm) ![Stars](https://img.shields.io/github/stars/apple/ml-fastvlm?style=social) ![Last Commit](https://img.shields.io/github/last-commit/apple/ml-fastvlm)
- From Pixels to Words -- Towards Native Vision-Language Primitives at Scale, arXiv 2025. `2B/9B`, [Paper](https://arxiv.org/abs/2510.14979),  [Github](https://github.com/EvolvingLMMs-Lab/NEO) ![Stars](https://img.shields.io/github/stars/EvolvingLMMs-Lab/NEO?style=social) ![Last Commit](https://img.shields.io/github/last-commit/EvolvingLMMs-Lab/NEO)

## SmallVLAs
> [Github]() ![Stars](https://img.shields.io/github/stars/?style=social) ![Last Commit](https://img.shields.io/github/last-commit/)
- [Awesome Vision Language Action (VLA) Models](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln?tab=readme-ov-file#-vision-language-action-vla-models) ![Stars](https://img.shields.io/github/stars/jonyzhang2023/awesome-embodied-vla-va-vln?style=social) ![Last Commit](https://img.shields.io/github/last-commit/jonyzhang2023/awesome-embodied-vla-va-vln)
- SmolVLA: A Vision-Language-Action Model for Affordable and Efficient Robotics, `0.24B-2.25B`, [Paper](https://arxiv.org/abs/2506.01844), [Github](https://github.com/huggingface/lerobot) ![Stars](https://img.shields.io/github/stars/huggingface/lerobot?style=social) ![Last Commit](https://img.shields.io/github/last-commit/huggingface/lerobot)
- X-VLA: Soft-Prompted Transformer as a Scalable Cross-Embodiment Vision-Language-Action Model, `0.9B`, [Paper](https://arxiv.org/pdf/2510.10274), [Github](https://github.com/2toinf/X-VLA) ![Stars](https://img.shields.io/github/stars/2toinf/X-VLA?style=social) ![Last Commit](https://img.shields.io/github/last-commit/2toinf/X-VLA)
- VLA-Adapter: An Effective Paradigm for Tiny-Scale Vision-Language-Action Model, `0.5B`, [Paper](https://arxiv.org/abs/2509.09372), [Github](https://github.com/OpenHelix-Team/VLA-Adapter) ![Stars](https://img.shields.io/github/stars/OpenHelix-Team/VLA-Adapter?style=social) ![Last Commit](https://img.shields.io/github/last-commit/OpenHelix-Team/VLA-Adapter)
- TinyVLA: Towards Fast, Data-Efficient Vision-Language-Action Models for Robotic Manipulation, R-AL 2025. `400M-1.3B`, [Paper](https://arxiv.org/abs/2409.12514), [Github](https://github.com/liyaxuanliyaxuan/TinyVLA) ![Stars](https://img.shields.io/github/stars/liyaxuanliyaxuan/TinyVLA?style=social) ![Last Commit](https://img.shields.io/github/last-commit/liyaxuanliyaxuan/TinyVLA)

## SpatialVLMs
> [Github]() ![Stars](https://img.shields.io/github/stars/?style=social) ![Last Commit](https://img.shields.io/github/last-commit/)
- DepthLM: Metric Depth From Vision Language Models, arxiv 2025. [Paper](https://arxiv.org/abs/2509.25413) [Model](https://huggingface.co/facebook/DepthLM) [Github](https://github.com/facebookresearch/DepthLM_Official) ![Stars](https://img.shields.io/github/stars/facebookresearch/DepthLM_Official?style=social) ![Last Commit](https://img.shields.io/github/last-commit/facebookresearch/DepthLM_Official)

